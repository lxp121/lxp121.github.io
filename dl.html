<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  Deep Learning - lxp121's BLOG on CUDA and DL
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="lxp121's BLOG on CUDA and DL" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:china.xipengli.com ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; lxp121's BLOG on CUDA and DL</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="dl.html">Deep Learning</a></li>
        
            <li><a href="cuda.html">CUDA</a></li>
        
            <li><a href="trt.html">TensorRT</a></li>
        
            <li><a href="Git.html">Git</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
	$(function(){
		$('#menu_item_index').addClass('is_active');
	});
</script>
<div class="row">
	<div class="large-8 medium-8 columns">
		<div class="markdown-body home-categories">
		
			<div class="article">
                <a class="clearlink" href="20180121_TF_to_TRT.html">
                
                  <h1>TensorFlow模型的保存，已经TensoRT中tensorFlow 模型的导入（草稿）</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	
                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2018/1/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='dl.html'>Deep Learning</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="20180116_DL_Tuning_Reprint.html">
                
                  <h1>深度学习中的优化调参细节（转帖）</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<h2 id="toc_0">深度学习中的技巧</h2>

<ul>
<li>初始化参数尽量小一些，这样 softmax 的回归输出更加接近均匀分布，使得刚开始网络并不确信数据属于哪一类；另一方面从数值优化上看我们希望我们的参数具有一致的方差（一致的数量级），这样我们的梯度下降法下降也会更快。同时为了使每一层的激励值保持一定的方差，我们在初始化参数（不包括偏置项）的方差可以与输入神经元的平方根成反比。</li>
<li>学习率（learning rate）的设置应该随着迭代次数的增加而减小，个人比较喜欢每迭代完一次epoch也就是整个数据过一遍，然后对学习率进行变化，这样能够保证每个样本得到了公平的对待。</li>
<li>滑动平均模型，在训练的过程中不断的对参数求滑动平均这样能够更有效的保持稳定性，使其对当前参数更新不敏感。例如加动量项的随机梯度下降法就是在学习率上应用滑动平均模型。</li>
<li>在验证集上微小的提升未必可信，一个常用的准则是增加了30个以上的正确样本，能够比较确信算法有了一定的提升。 </li>
<li>不要太相信模型开始的学习速度，这与最终的结果基本没有什么关系。一个低的学习速率往往能得到较好的模型。</li>
<li>在深度学习中，常用的防止过拟合的方法除了正则化，dropout和pooling之外，还有提前停止训练的方法——就是看到我们在验证集的上的正确率开始下降就停止训练。</li>
<li>当激活函数是RELU时，我们在初始化偏置项时，为了避免过多的死亡节点（激活值为0）一般可以初始化为一个较小的正值。</li>
<li>基于随机梯度下降的改进优化算法有很多种，在不熟悉调参的情况，建议使用Adam方法</li>
<li>训练过程不仅要观察训练集和测试集的loss是否下降、正确率是否提高，对于参数以及激活值的分布情况也要及时观察，要有一定的波动。</li>
<li>如果我们设计的网络不work，在训练集的正确率也很低的话，我们可以减小样本数量同时去掉正则化项，然后进行调参，如果正确率还是不高的话，就说明我们设计的网络结果可能有问题。</li>
<li>fine-tuning的时候，可以把新加层的学习率调高，重用层的学习率可以设置的相对较低。</li>
<li>在隐藏层的激活函数，tanh往往比sigmoid表现更好。</li>
<li>针对梯度爆炸的情况我们可以使用梯度截断来解决，尤其在RNN中由于存在相同的循环结构，导致相同参数矩阵的连乘，更加容易产生梯度爆炸。当然，使用LSTM和GRU等更加优化的模型往往是更好地选择。</li>
<li>正则化输入，也就是让特征都保持在0均值和1方差。（注意做特征变换时请保持训练集合测试集进行了相同的变化）</li>
<li>梯度检验：当我们的算法在训练出现问题而进行debug时，可以考虑使用近似的数值梯度和计算的梯度作比较检验梯度是否计算正确。</li>
<li>搜索超参数时针对经典的网格搜索方法，这里有两点可以改善的地方：1）不用网格，用随机值，因为这样我们一次实验参数覆盖范围更广，尤其在参数对结果影响级别相差很大的情况下。2）不同数量级的搜索密度是不一样的，不能均分。</li>
</ul>

<h2 id="toc_1">CNN中的独特技巧</h2>

<ul>
<li>CNN中将一个大尺寸的卷积核可以分解为多层的小尺寸卷积核或者分成多层的一维卷积。这样能够减少参数增加非线性。</li>
<li>CNN中的网络设计应该是逐渐减小图像尺寸，同时增加通道数，让空间信息转化为高阶抽象的特征信息。</li>
<li>CNN中可以利用Inception方法来提取不同抽象程度的高阶特征，用ResNet的思想来加深网络的层数。</li>
<li>CNN处理图像时，常常会对原图进行旋转、裁剪、亮度、色度、饱和度等变化以增大数据集增加鲁棒性。</li>
</ul>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2018/1/16</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='dl.html'>Deep Learning</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
			<div class="article">
                <a class="clearlink" href="15112406136583.html">
                
                  <h1>RNNs with equations</h1>
                  <div class="a-content">
                      
                      <div class="a-content-text">
                        
                        	<p>实际上使用公式来理解RNN更加简单，例如LSTM实际上就是求解了三个门i (input), o(output), f(forget), 三个门就是三个全连接层+激活层。而所谓的cell，就是计算输入的信息（本时刻，和上个时刻），至于这些信息是否保留，是两个门forget gate 和input gate来保证的。</p>

<h2 id="toc_0">LSTM</h2>

<ul>
<li>f: forget gate, 遗忘门，上一时刻的\(C_{t-1}\)的权重</li>
<li>i: input gate, 输入门，当前计算的\(C_{t}\)的权重</li>
<li>o: output gate, 输出门，当前计算的\(C_{t}\)到hidden output的权重。</li>
</ul>

<p>\[ f_t = \sigma(W_f\cdot [h_{t-1},x_t]^T+b_f)\]<br/>
\[ i_t = \sigma(W_i\cdot [h_{t-1},x_t]^T+b_i)\]<br/>
\[ \tilde{C}_t = \tanh (W_c\cdot [h_{t-1},x_t]^T+b_c)\]<br/>
\[ o_t = \sigma(W_o\cdot [h_{t-1},x_t]^T+b_o)\]<br/>
\[ C_t = f_t C_{t-1} + i_t  \tilde{C}_t \]<br/>
\[ h_t = o_t \tanh(C_t) \]</p>

<h2 id="toc_1">LSTM with peephole</h2>

<p>和LSTM相比，在计算各个gate的时候，顺便参考了一下\(C_{t-1}\)(input, forget)或者\(C_t\)(output)</p>

<p>\[ f_t = \sigma(W_f\cdot [C_{t-1},h_{t-1},x_t]^T+b_f)\]<br/>
\[ i_t = \sigma(W_i\cdot [C_{t-1},h_{t-1},x_t]^T+b_i)\]<br/>
\[ \tilde{C}_t = \tanh (W_c\cdot [h_{t-1},x_t]^T+b_c)\]<br/>
\[ C_t = f_t C_{t-1} + i_t  \tilde{C}_t \]<br/>
\[ o_t = \sigma(W_o\cdot [C_t,h_{t-1},x_t]^T+b_o)\]<br/>
\[ h_t = o_t \tanh(C_t) \]</p>

<h2 id="toc_2">LSTMP</h2>

<p>和LSTM相比，在计算最终的hidden output的时候，多添加了一个\(W_r\)<br/>
\[ f_t = \sigma(W_f\cdot [h_{t-1},x_t]^T+b_f)\]<br/>
\[ i_t = \sigma(W_i\cdot [h_{t-1},x_t]^T+b_i)\]<br/>
\[ \tilde{C}_t = \tanh (W_c\cdot [h_{t-1},x_t]^T+b_c)\]<br/>
\[ o_t = \sigma(W_o\cdot [h_{t-1},x_t]^T+b_o)\]<br/>
\[ C_t = f_t C_{t-1} + i_t  \tilde{C}_t \]<br/>
\[ h_t = W_r (o_t \tanh(C_t)) \]</p>

<h2 id="toc_3">GRU</h2>

<p>GRU相比LSTM更加简单，它只有两个门(z,r), 并且不需要单独的cell单元来保存状态。<br/>
\[ z_t = \sigma(W_z\cdot [h_{t-1}, x_t]^T)\]<br/>
\[ r_t = \sigma(W_r\cdot [h_{t-1}, x_t]^T)\]<br/>
\[ \tilde{h}_t = \tanh(W\cdot [r_t\times h_{t-1}, x_t]^T)\]<br/>
\[ h_t = (1-z_t)h_{t-1} + z_t \tilde{h}_t\]</p>

                        
                      </div>
                  </div>
                </a>
                <div class="read-more clearfix">
                  <div class="more-left left">
                  
                    <span class="date">2017/11/21</span>
                    <span>posted in&nbsp;</span> 
          				  
          					    <span class="posted-in"><a href='dl.html'>Deep Learning</a></span>
          				   
                  </div>
                  <div class="more-right right">
                  <span class="comments">
                      

                       
                  </span>
                  </div>
                </div>
              </div><!-- article -->
        
              


			<div class="row">
			  <div class="large-6 columns">
			  <p class="text-left" style="padding-top:25px;">
			   
			  </p>
			  </div>
			  <div class="large-6 columns">
			<p class="text-right" style="padding-top:25px;">
			
			</p>
			  </div>
			</div>
		</div>
	</div><!-- large 8 -->

 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="media/15161603048345/Blog_LOGO.png" /></div>
            
                <h1>lxp121's BLOG on CUDA and DL</h1>
                <div class="site-des"></div>
                <div class="social">



<a target="_blank" class="linkedin" href="https://www.linkedin.com/in/xipengli" title="LinkedIn">LinkedIn</a>





<a target="_blank" class="github" target="_blank" href="https://github.com/lxp121" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:lxp121@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="dl.html"><strong>Deep Learning</strong></a>
        
            <a href="cuda.html"><strong>CUDA</strong></a>
        
            <a href="trt.html"><strong>TensorRT</strong></a>
        
            <a href="Git.html"><strong>Git</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="20180212_git_gitignore.html">Git 修改.gitignore不起作用</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180212_git_move_commits_to_new_branch.html">Git 将最近改动移到新的分支(branch)上</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180125_CUDA_Warp_Level_Primitives.html">使用 CUDA 的 warp-level 原语</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180121_CUDA_Volatile_And_Memory_Fence.html">Volatile 限定词（Qualifier）和内存围栏（memory fence)</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180121_TF_to_TRT.html">TensorFlow模型的保存，已经TensoRT中tensorFlow 模型的导入（草稿）</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
