<!doctype html>
<html class="no-js" lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
    
  使用 CUDA 的 warp-level 原语 - lxp121's BLOG on CUDA and DL
  
  </title>
  
  
  <link href="atom.xml" rel="alternate" title="lxp121's BLOG on CUDA and DL" type="application/atom+xml">
    <link rel="stylesheet" href="asset/css/foundation.min.css" />
    <link rel="stylesheet" href="asset/css/docs.css" />
    <script src="asset/js/vendor/modernizr.js"></script>
    <script src="asset/js/vendor/jquery.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/github.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  function before_search(){
    var searchVal = 'site:china.xipengli.com ' + document.getElementById('search_input').value;
    document.getElementById('search_q').value = searchVal;
    return true;
  }
</script>
  </head>
  <body class="antialiased hide-extras">
    
    <div class="marketing off-canvas-wrap" data-offcanvas>
      <div class="inner-wrap">


<nav class="top-bar docs-bar hide-for-small" data-topbar>


  <section class="top-bar-section">
  <div class="row">
      <div style="position: relative;width:100%;"><div style="position: absolute; width:100%;">
        <ul id="main-menu" class="left">
        
        <li id=""><a target="_self" href="index.html">Home</a></li>
        
        <li id=""><a target="_self" href="archives.html">Archives</a></li>
        
        <li id=""><a target="_self" href="about.html">About</a></li>
        
        </ul>

        <ul class="right" id="search-wrap">
          <li>
<form target="_blank" onsubmit="return before_search();" action="http://google.com/search" method="get">
    <input type="hidden" id="search_q" name="q" value="" />
    <input tabindex="1" type="search" id="search_input"  placeholder="Search"/>
</form>
</li>
          </ul>
      </div></div>
  </div>
  </section>

</nav>

        <nav class="tab-bar show-for-small">
  <a href="javascript:void(0)" class="left-off-canvas-toggle menu-icon">
    <span> &nbsp; lxp121's BLOG on CUDA and DL</span>
  </a>
</nav>

<aside class="left-off-canvas-menu">
      <ul class="off-canvas-list">
       
       <li><a href="index.html">HOME</a></li>
    <li><a href="archives.html">Archives</a></li>
    <li><a href="about.html">ABOUT</a></li>

    <li><label>Categories</label></li>

        
            <li><a href="dl.html">Deep Learning</a></li>
        
            <li><a href="cuda.html">CUDA</a></li>
        
            <li><a href="trt.html">TensorRT</a></li>
        
            <li><a href="Git.html">Git</a></li>
         

      </ul>
    </aside>

<a class="exit-off-canvas" href="#"></a>


        <section id="main-content" role="main" class="scroll-container">
        
       

 <script type="text/javascript">
  $(function(){
    $('#menu_item_index').addClass('is_active');
  });
</script>
<div class="row">
  <div class="large-8 medium-8 columns">
      <div class="markdown-body article-wrap">
       <div class="article">
          
          <h1>使用 CUDA 的 warp-level 原语</h1>
     
        <div class="read-more clearfix">
          <span class="date">2018/1/25</span>

          <span>posted in&nbsp;</span> 
          
              <span class="posted-in"><a href='cuda.html'>CUDA</a></span>
           
         
          <span class="comments">
            

            
          </span>

        </div>
      </div><!-- article -->

      <div class="article-content">
      <p>本文是NVIDA Blog文章<a href="https://devblogs.nvidia.com/using-cuda-warp-level-primitives/">Using CUDA Warp-Level Primitives</a>的全文翻译和深度解析。</p>

<p>从CUDA 9.0 开始，CUDA引入了更加灵活的group的选择，这一方面使得CUDA编程更加简单，一方面也使得一些原有的功能发生了一些改变。本文重点对warp级别的原语（primitives）进行一些介绍。</p>

<p>在GPU中，线程（thread）被组织为warp，然后warp会按照SIMT（单指令多线程，Single Instruction Multiple Thread）的形式来执行。很多CUDA程序都可以通过充分利用warp执行来达到很高的性能。</p>

<h2 id="toc_0">Warp级别原语（Warp-level Primitives）</h2>

<p>NVIDIA GPUs和CUDA编程模型使用一种被称为SIMT的执行模式。SIMT和SIMD（Single Instruction, Multiple Data)的区别主要是：</p>

<ul>
<li>在SIMD架构中，每个指令在不同的数据上并行的进行相同的操作。SIMD通常采用向量寄存器和向量执行单元来实现。而vector执行是通过一个标量的向量来实现的。简言之，一个线程调度，多个向量寄存器和执行单元上并行完成相同指令。</li>
<li>而SIMT架构中，并不只是使用单一的线程，并且数据也不要求采用向量存储方式。多个线程会发起普通的指令（而非向量指令）在任意数据上执行。我们可以想象一下GPU的执行时候，可以根据每个thread的线程来计算需要操作的数据位置。实际上，可以再SIMT的架构中进一步实现SIMD的子架构，以Pascal架构中支持的INT8计算模式为例。该模式可以非常高效地提高深度神经网络的计算。在INT8的计算中，要求被计算的4个数据相互邻近（每个8bit），4个指令在一个GPU线程上执行。而这个线程是SIMT中的一个线程。</li>
</ul>

<p>在NVIDIA的GPU上，32个并行线程（相邻线程）被组成一个warp，每一个线程可以访问它自己的寄存器，从不同地址（可以不相邻）读写数据。并且，这些线程是可以支持分歧的控制流路径（divergent control flow paths)。本文中，我们重点放在使用Warp级别原语的使用。</p>

<p><em><a href="#code1">代码1</a></em> 是一个warp-level 原语的例子。我们使用了一个<strong>__shfl_down_sync()</strong> 来实现一个tree-reduction方式来计算一个warp中线程val值得和。该代码执行完之后，warp中的第一个线程中的val值就等于最终的和。</p>

<p><strong><div align = lift><span id="code1">代码1: warp-level reduction</span></div></strong> </p>

<pre><code class="language-cpp">#define FULL_MASK 0xffffffff
for (int offset = 16; offset &gt; 0; offset /= 2)
    val += __shfl_down_sync(FULL_MASK, val, offset);
</code></pre>

<p>这个计算可以用下面的图来说明：<br/>
<img src="media/15168532667210/15171231191469.png" alt="使用__shlf_down_sync()来实现warp级别的并行reduction"/><br/>
<strong><div align = center><span id="image1">图片1：使用__shlf_down_sync()来实现warp级别的并行reduction</span></div></strong></p>

<p>一个warp中包含32通道（lane），每一个线程占用一个通道。对于处于 X 通道的线程，<strong>__shlf_down_sync(FULL_MASK, val, offset)</strong> 来获得在同一个warp中的第 <strong>X+offset</strong> 航道的val值。这一数据交换在regitster中进行的，因此其效率高于共享内存。使用共享内存需要一次读，一次写，并且需要一个额外的寄存器来保存这些地址。</p>

<p>CUDA 9中包含了三类warp级别原语：</p>

<ol>
<li>同步地数据交换（Synchronized data exchange）：在同一warp中不同thread之间交换数据：

<ul>
<li>__all_sync, __any_sync, __uni_sync, __ballot_sync</li>
<li>__shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync</li>
<li>__match_any_sync, __match_all_sync</li>
</ul></li>
<li>Active mask query: 返回一个32-bit的mask来表示warp中哪些thread是活动的。

<ul>
<li>__activemask</li>
</ul></li>
<li>线程同步（Thread synchronization)：同步warp中的线程，并提供一个内存围栏（关于内存围栏的概念，可以在<a href="20180121_CUDA_Volatile_And_Memory_Fence.html">Volatile 限定词（Qualifier）和内存围栏（memory fence) </a>中找到详细解释）。</li>
</ol>

<h2 id="toc_1">同步地数据交换（Synchronized data exchange）</h2>

<p>每一个”同步地数据交换“原语都会在warp中的一组线程（不一定是所有线程）上执行一个聚合操作（collective operation)。</p>

<p>Each of the “synchronized data exchange” primitives perform a collective operation among a set of threads in a warp. For example, Listing 2 shows three of these. Each thread that calls __shfl_sync() or __shfl_down_sync() receives data from a thread in the same warp, and each thread that calls __ballot_sync() receives a bit mask representing all the threads in the warp that pass a true value for the predicate argument.</p>

<p><strong><div align = lift><span id="code2">代码2: Synchronized data exchange warp-level primitives</span></div></strong> </p>

<pre><code class="language-cpp">int __shfl_sync(unsigned mask, int val, int src_line, int width=warpSize);
int __shfl_down_sync(unsigned mask, int var, unsigned detla, 
                     int width=warpSize);
int __ballot_sync(unsigned mask, int predicate);
</code></pre>

<p>The set of threads that participates in invoking each primitive is specified using a 32-bit mask, which is the first argument of these primitives. All the participating threads must be synchronized for the collective operation to work correctly. Therefore, these primitives first synchronize the threads if they are not already synchronized.</p>

<p>A frequently asked question is “what should I use for the mask argument?”. You can consider the mask to mean the set of threads in the warp that should participate in the collective operation. This set of threads is determined by the program logic, and can usually be computed by some branch condition earlier in the program flow. Take the reduction code in Listing 1 as an example. Assume we want to compute the sum of all the elements of an array input[], whose size NUM_ELEMENTS is less than the number of threads in the thread block. We can use the method in Listing 3.</p>

<p><strong><div align = lift><span id="code3">代码3: </span></div></strong> </p>

<pre><code class="language-cpp">unsigned mask = __ballot_sync(FULL_MASK, threadIdx.x &lt; NUM_ELEMENTS);
if (threadIdx.x &lt; NUM_ELEMENTS) { 
    val = input[threadIdx.x]; 
    for (int offset = 16; offset &gt; 0; offset /= 2)
        val += __shfl_down_sync(mask, val, offset);
    …
}
</code></pre>

<p>The code uses the condition thread.idx.x &lt; NUM_ELEMENTS to determine whether or not a thread will participate in the reduction.  __ballot_sync() is used to compute the membership mask for the __shfl_down_sync() operation. __ballot_sync() itself uses FULL_MASK (0xffffffff for 32 threads) because we assume all threads will execute it.</p>

<p>On Volta and later GPU architectures, the data exchange primitives can be used in thread-divergent branches: branches where some threads in the warp take a different path than the others. Listing 4 shows an example where all the threads in a warp get the value of val from the thread at lane 0. The even- and odd-numbered threads take different branches of an if statement.</p>

<p><strong><div align = lift><span id="code4">代码4: </span></div></strong> </p>

<pre><code class="language-cpp">if (threadIdx.x % 2) {
    val += __shfl_sync(FULL_MASK, val, 0);
…
}
else {
val += __shfl_sync(FULL_MASK, val, 0);
…
}
</code></pre>

<p>On the latest Volta (and future) GPUs, you can run library functions that use warp synchronous primitives without worrying whether the function is called in a thread-divergent branch.</p>

<h2 id="toc_2">Active Mask Query</h2>

<p>__activemask() returns a 32-bit unsigned int mask of all currently active threads in the calling warp. In other words, it shows the calling thread which threads in its warp are also executing the same __activemask(). This is useful for the :opportunistic warp-level programming” technique we explain later, as well as for debugging and understanding program behavior.</p>

<p>However, it’s important to use __active_mask() correctly. Listing 5 illustrates an incorrect use. The code tries to perform the same sum reduction  shown in Listing 4, but instead of using __ballot_sync() to compute the mask before the branch, it uses __active_mask() inside the branch. This is incorrect, as it would result in partial sums instead of a total sum. The CUDA execution model does not guarantee that all threads taking the branch together will execute the __active_mask() together. Implicit lock step execution is not guaranteed, as we will explain.</p>

<p><strong><div align = lift><span id="code5">代码5: </span></div></strong> </p>

<pre><code class="language-cpp">//
// Incorrect use of __active_mask()
//
if (threadIdx.x &lt; NUM_ELEMENTS) { 
    unsigned mask = __active_mask(); 
    val = input[threadIdx.x]; 
    for (int offset = 16; offset &gt; 0; offset /= 2)
        val += __shfl_down_sync(mask, val, offset);
    …
}
</code></pre>

<h2 id="toc_3">Warp 同步（Synchronization）</h2>

<p>When threads in a warp need to perform more complicated communications or collective operations than what the data exchange primitives provide, you can use the __syncwarp() primitive to synchronize threads in a warp. It is similar to the __syncthreads() primitive (which synchronizes all threads in the thread block) but at finer granularity.</p>

<pre><code class="language-cpp">void __syncwarp(unsigned mask=FULL_MASK);
</code></pre>

<p>The __syncwarp() primitive causes the executing thread to wait until all threads specified in mask have executed a __syncwarp() (with the same mask) before resuming execution. It also provides a memory fence to allow threads to communicate via memory before and after calling the primitive.</p>

<p>Listing 6 shows an example of shuffling the ownership of matrix elements among threads in a warp.</p>

<pre><code class="language-cpp">float val = get_value(…);
__shared__ float smem[4][8];
 
//   0  1  2  3  4  5  6  7 
//   8  9 10 11 12 13 14 15 
//  16 17 18 19 20 21 22 23
//  24 25 26 27 28 29 30 31
int x1 = threadIdx.x % 8;
int y1 = threadIdx.x / 8;
 
//   0  4  8 12 16 20 24 28
//   1  5 10 13 17 21 25 29
//   2  6 11 14 18 22 26 30
//   3  7 12 15 19 23 27 31
int x2= threadIdx.x / 4;
int y2 = threadIdx.x % 4;
 
smem[y1][x1] = val;
__syncwarp();
val = smem[y2][x2];
 
use(val);
</code></pre>

<p>Assume a 1-D thread block is used (i.e. threadIdx.y is always 0). At the beginning of the code, each thread in a warp owns one element of a 4×8 matrix with row-major indexing. In other words, lane 0 owns [0][0] and lane 1 owns [0][1]. Each thread stores its value into the corresponding position of a 4×8 array in shared memory. Then __syncwarp() is used to ensure all threads have done the store, before each thread reads from a transposed position in the array. In the end, each thread in the warp owns one element of the matrix with column-major indexing: lane 0 owns [0][0] and lane 1 owns [1][0].</p>

<p>Make sure that __syncwarp() separates shared memory reads and writes to avoid race conditions. Listing 7 illustrates an incorrect use in a tree sum reduction in shared memory. There is a shared memory read followed by a shared memory write between every two __syncwarp() calls. The CUDA programming model does not guarantee that all the reads will be performed before all the writes, so there is a race condition.</p>

<pre><code class="language-cpp">unsigned tid = threadIdx.x;

// Incorrect use of __syncwarp()
shmem[tid] += shmem[tid+16]; __syncwarp();
shmem[tid] += shmem[tid+8];  __syncwarp();
shmem[tid] += shmem[tid+4];  __syncwarp();
shmem[tid] += shmem[tid+2];  __syncwarp();
shmem[tid] += shmem[tid+1];  __syncwarp();
</code></pre>

<p>Listing 8 fixes the race condition by inserting extra __syncwarp() calls. The CUDA compiler may elide some of these synchronization instructions in the final generated code depending on the target architecture (e.g. on pre-Volta architectures).</p>

<pre><code class="language-cpp">unsigned tid = threadIdx.x;
int v = 0;

v += shmem[tid+16]; __syncwarp();
shmem[tid] = v;     __syncwarp();
v += shmem[tid+8];  __syncwarp();
shmem[tid] = v;     __syncwarp();
v += shmem[tid+4];  __syncwarp();
shmem[tid] = v;     __syncwarp();
v += shmem[tid+2];  __syncwarp();
shmem[tid] = v;     __syncwarp();
v += shmem[tid+1];  __syncwarp();
shmem[tid] = v;
</code></pre>

<p>On the latest Volta (and future) GPUs, you can also use __syncwarp() in thread-divergent branches to synchronize threads from both branches. But once they return from the primitive, the threads will become divergent again. See Listing 13 for such an example.</p>

<h2 id="toc_4">Opportunistic Warp-level Programming</h2>

<p>As we showed in the Synchronized Data Exchange section, the membership mask used in the synchronized data exchange primitives is often computed before a branch condition in the program flow. In many cases, the program needs to pass the mask along the program flow; for example, as a function argument when warp-level primitives are used inside a function. This may be difficult if you want to use warp-level programming inside a library function but you cannot change the function interface.</p>

<p>Some computations can use whatever threads happen to be executing together. We can use a technique called opportunistic warp-level programming, as the following example illustrates. (See this post on warp-aggregated atomics for more information on the algorithm, and this post for discussion of how Cooperative Groups makes the implementation much simpler.)</p>

<pre><code class="language-cpp">// increment the value at ptr by 1 and return the old value
__device__ int atomicAggInc(int *ptr) {
    int pred;
    int mask = __match_all_sync(__activemask(), ptr, &amp;pred);
    int leader = __ffs(mask) – 1;    // select a leader
    int res;
    if(lane_id() == leader)                  // leader does the update
        res = atomicAdd(ptr, __popc(mask));
    res = __shfl_sync(mask, res, leader);    // get leader’s old value
    return res + __popc(mask &amp; ((1 &lt;&lt; lane_id()) – 1)); //compute old value
}
</code></pre>

<p>atomicAggInc() atomically increments the value pointed to by ptr by 1 and returns the old value. It uses the atomicAdd() function, which may incur contention. To reduce contention, atomicAggInc replaces the per-thread atomicAdd() operation with a per-warp atomicAdd(). The __activemask() in line 4 finds the set of threads in the warp that are about to perform the atomic operation. __match_all_sync() returns the bit mask of the threads that have the same value ptr, partitioning the incoming threads into groups whose members have the same ptr value. Each group elects a leader thread (line 5), which performs the atomicAdd() (line 8) for the whole group. Every thread gets the old value from the leader (line 9) returned by the atomicAdd(). Line 10 computes and returns the old value the current thread would get from atomicInc() if it were to call the function instead of atomicAggInc.</p>

<h2 id="toc_5">Implicit Warp-Synchronous Programming is Unsafe</h2>

<p>CUDA toolkits prior to version 9.0 provided a (now legacy) version of warp-level primitives. Compared with the CUDA 9 primitives, the legacy primitives do not accept a mask argument. For example, int __any(int predicate) is the legacy version of int __any_sync(unsigned mask, int predicate).</p>

<p>The mask argument, as explained previously, specifies the set of threads in a warp that must participate in the primitives. The new primitives perform intra-warp thread-level synchronization if the threads specified by the mask are not already synchronized during execution.</p>

<p>The legacy warp-level primitives do not allow programmers to specify the required threads and do not perform synchronization. Therefore, the threads that must participate in the warp-level operation are not explicitly expressed by the CUDA program. The correctness of such a program depends on implicit warp-synchronous behavior, which may change from one hardware architecture to another, from one CUDA toolkit release to another (due to changes in compiler optimizations, for example), or even from one run-time execution to another. Such implicit warp-synchronous programming is unsafe and may not work correctly.</p>

<p>For example, in the following code, let’s assume all 32 threads in a warp execute line 2 together. The if statement at line 4 causes the threads to diverge, with the odd threads calling foo() at line 5 and the even threads calling bar() at line 8.</p>

<pre><code class="language-cpp">// Assuming all 32 threads in a warp execute line 1 together.
assert(__ballot(1) == FULL_MASK);
int result;
if (thread_id % 2) {
    result = foo();
}
else {
    result = bar();
}
unsigned ballot_result = __ballot(result);
</code></pre>

<p>The CUDA compiler and the hardware will try to re-converge the threads at line 10 for better performance. But this re-convergence is not guaranteed. Therefore, the ballot_result may not contain the ballot result from all 32 threads.</p>

<p>Calling the new __syncwarp() primitive at line 10 before __ballot(), as illustrated in Listing 11, does not fix the problem either. This is again implicit warp-synchronous programming. It assumes that threads in the same warp that are once synchronized will stay synchronized until the next thread-divergent branch. Although it is often true, it is not guaranteed in the CUDA programming model.</p>

<pre><code class="language-cpp">__syncwarp();
unsigned ballot_result = __ballot(result);
</code></pre>

<p>The correct fix is to use __ballot_sync() as in Listing 12.</p>

<pre><code class="language-cpp">unsigned ballot_result = __ballot_sync(FULL_MASK, result);
</code></pre>

<p>A common mistake is to assume that calling __syncwarp() before and/or after a legacy warp-level primitive is functionally equivalent to calling the sync version of the primitive. For example, is __syncwarp(); v = __shfl(0); __syncwarp(); the same as __shfl_sync(FULL_MASK, 0)? The answer is no, for two reasons. First, if the sequence is used in a thread-divergent branch, then __shfl(0) won’t be executed by all threads together. Listing 13 shows an example. The __syncwarp() at line 3 and line 7 would ensure foo() is called by all threads in the warp before line 4 or line 8 is executed. Once threads leave the __syncwarp(), the odd threads and the even threads become divergent again. Therefore, the __shfl(0) at line 4 will get an undefined value because lane 0 is inactive when line 4 is executed. __shfl_sync(FULL_MASK, 0) can be used in thread-divergent branches without this problem.</p>

<pre><code class="language-cpp">v = foo();
if (threadIdx.x % 2) {
    __syncwarp();
    v = __shfl(0);       // L3 will get undefined result because lane 0 
    __syncwarp();        // is not active when L3 is executed. L3 and L6
} else {                 // will execute divergently.
    __syncwarp();
    v = __shfl(0);
    __syncwarp();
}
</code></pre>

<p>Second, even when the sequence is called by all the threads together, the CUDA execution model does not guarantee threads will stay convergent after leaving __syncwarp(), as Listing 14 shows. Implicit lock-step execution is not guaranteed. Remember, thread convergence is guaranteed only within explicitly synchronous warp-level primitives.</p>

<pre><code class="language-cpp">assert(__activemask() == FULL_MASK); // assume this is true
__syncwarp();
assert(__activemask() == FULL_MASK); // this may fail
</code></pre>

<p>Because using them can lead to unsafe programs, the legacy warp-level primitives are deprecated starting in CUDA 9.0.</p>

<h2 id="toc_6">Update Legacy Warp-Level Programming</h2>

<p>If your program uses legacy warp-level primitives or any form of implicit warp-synchronous programming (such as communicating between threads of a warp without synchronization), you should  update the code to use the sync version of the primitives. You may also want to restructure your code to use Cooperative Groups, which provides a higher level of abstraction as well as new features such as multi-block synchronization.</p>

<p>The trickiest part of using the warp-level primitives is figuring out the membership mask to be used. We hope the above sections give you a good idea where to start and what to look out for.  Here is a list of suggestions:</p>

<ol>
<li>Don’t just use FULL_MASK (i.e. 0xffffffff for 32 threads) as the mask value. If not all threads in the warp can reach the primitive according to the program logic, then using FULL_MASK may cause the program to hang.</li>
<li>Don’t just use __activemask() as the mask value. __activemask() tells you what threads happen to be convergent when the function is called, which can be different from what you want to be in the collective operation.</li>
<li>Do analyze the program logic and understand the membership requirements. Compute the mask ahead based on your program logic.</li>
<li>If your program does opportunistic warp-synchronous programming, use “detective” functions such as __activemask() and __match_all_sync() to find the right mask.</li>
<li>Use __syncwarp() to separate operations with intra-warp dependences. Do not assume lock-step execution.</li>
</ol>

<p>One last trick. If your existing CUDA program gives a different result on Volta architecture GPUs, and you suspect the difference is caused by Volta’s new independent thread scheduling which can change warp synchronous behavior, you may want to recompile your program with nvcc options -arch=compute_60 -code=sm_70. Such compiled programs opt-in to Pascal’s thread scheduling. When used selectively, it can help pin down the culprit module more quickly, allowing you to update the code to avoid implicit warp-synchronous programming.</p>

<p><img src="media/15168532667210/15171479419797.png" alt=""/><br/>
<strong><div align = center><span id="image2">图片2：Volta independent thread scheduling enables interleaved execution of statements from divergent branches. This enables execution of fine-grain parallel algorithms where threads within a warp may synchronize and communicate.</span></div></strong></p>


    

      </div>

      <div class="row">
        <div class="large-6 columns">
        <p class="text-left" style="padding:15px 0px;">
      
          <a href="20180212_git_move_commits_to_new_branch.html" 
          title="Previous Post: Git 将最近改动移到新的分支(branch)上">&laquo; Git 将最近改动移到新的分支(branch)上</a>
      
        </p>
        </div>
        <div class="large-6 columns">
      <p class="text-right" style="padding:15px 0px;">
      
          <a  href="20180121_CUDA_Volatile_And_Memory_Fence.html" 
          title="Next Post: Volatile 限定词（Qualifier）和内存围栏（memory fence)">Volatile 限定词（Qualifier）和内存围栏（memory fence) &raquo;</a>
      
      </p>
        </div>
      </div>
      <div class="comments-wrap">
        <div class="share-comments">
          

          

          
        </div>
      </div>
    </div><!-- article-wrap -->
  </div><!-- large 8 -->




 <div class="large-4 medium-4 columns">
  <div class="hide-for-small">
    <div id="sidebar" class="sidebar">
          <div id="site-info" class="site-info">
            
                <div class="site-a-logo"><img src="media/15161603048345/Blog_LOGO.png" /></div>
            
                <h1>lxp121's BLOG on CUDA and DL</h1>
                <div class="site-des"></div>
                <div class="social">



<a target="_blank" class="linkedin" href="https://www.linkedin.com/in/xipengli" title="LinkedIn">LinkedIn</a>





<a target="_blank" class="github" target="_blank" href="https://github.com/lxp121" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:lxp121@gmail.com" title="Email">Email</a>
  <a target="_blank" class="rss" href="atom.xml" title="RSS">RSS</a>
                
              	 </div>
          	</div>

             

              <div id="site-categories" class="side-item ">
                <div class="side-header">
                  <h2>Categories</h2>
                </div>
                <div class="side-content">

      	<p class="cat-list">
        
            <a href="dl.html"><strong>Deep Learning</strong></a>
        
            <a href="cuda.html"><strong>CUDA</strong></a>
        
            <a href="trt.html"><strong>TensorRT</strong></a>
        
            <a href="Git.html"><strong>Git</strong></a>
         
        </p>


                </div>
              </div>

              <div id="site-categories" class="side-item">
                <div class="side-header">
                  <h2>Recent Posts</h2>
                </div>
                <div class="side-content">
                <ul class="posts-list">
	      
		      
			      <li class="post">
			        <a href="20180212_git_gitignore.html">Git 修改.gitignore不起作用</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180212_git_move_commits_to_new_branch.html">Git 将最近改动移到新的分支(branch)上</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180125_CUDA_Warp_Level_Primitives.html">使用 CUDA 的 warp-level 原语</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180121_CUDA_Volatile_And_Memory_Fence.html">Volatile 限定词（Qualifier）和内存围栏（memory fence)</a>
			      </li>
		     
		  
		      
			      <li class="post">
			        <a href="20180121_TF_to_TRT.html">TensorFlow模型的保存，已经TensoRT中tensorFlow 模型的导入（草稿）</a>
			      </li>
		     
		  
		      
		  
		      
		  
		      
		   
		  		</ul>
                </div>
              </div>
        </div><!-- sidebar -->
      </div><!-- hide for small -->
</div><!-- large 4 -->

</div><!-- row -->

 <div class="page-bottom clearfix">
  <div class="row">
   <p class="copyright">Copyright &copy; 2015
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a>,&nbsp; 
Theme used <a target="_blank" href="http://github.com">GitHub CSS</a>.</p>
  </div>
</div>

        </section>
      </div>
    </div>

  
    

    <script src="asset/js/foundation.min.js"></script>
    <script>
      $(document).foundation();
      function fixSidebarHeight(){
        var w1 = $('.markdown-body').height();
          var w2 = $('#sidebar').height();
          if (w1 > w2) { $('#sidebar').height(w1); };
      }
      $(function(){
        fixSidebarHeight();
      })
      $(window).load(function(){
          fixSidebarHeight();
      });
     
    </script>

    <script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>


  </body>
</html>
